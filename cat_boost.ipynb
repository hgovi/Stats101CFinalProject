{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "test = pd.read_csv(\"data/aluminum_coldRoll_testNoY.csv\")\n",
    "train = pd.read_csv(\"data/aluminum_coldRoll_train.csv\")\n",
    "alloy = pd.read_csv(\"data/ally.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure alloy column is string (important!)\n",
    "train[\"alloy\"] = train[\"alloy\"].astype(str)\n",
    "test[\"alloy\"] = test[\"alloy\"].astype(str)\n",
    "alloy[\"alloy\"] = alloy[\"alloy\"].astype(str)\n",
    "\n",
    "# Merge the composition columns into train/test\n",
    "train = train.merge(alloy, on=\"alloy\", how=\"left\")\n",
    "test = test.merge(alloy, on=\"alloy\", how=\"left\")\n",
    "test_ids = test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   ID                      160000 non-null  int64  \n",
      " 1   alloy                   160000 non-null  object \n",
      " 2   cutTemp                 160000 non-null  object \n",
      " 3   rollTemp                160000 non-null  object \n",
      " 4   firstPassRollPressure   160000 non-null  int64  \n",
      " 5   secondPassRollPressure  160000 non-null  int64  \n",
      " 6   topEdgeMicroChipping    160000 non-null  object \n",
      " 7   blockSource             160000 non-null  object \n",
      " 8   machineRestart          160000 non-null  object \n",
      " 9   contourDefNdx           160000 non-null  int64  \n",
      " 10  clearPassNdx            160000 non-null  float64\n",
      " 11  Cu                      160000 non-null  float64\n",
      " 12  Mg                      160000 non-null  float64\n",
      " 13  Mn                      160000 non-null  float64\n",
      " 14  Si                      160000 non-null  float64\n",
      " 15  Zn                      160000 non-null  float64\n",
      " 16  Cr                      160000 non-null  float64\n",
      " 17  Fe                      160000 non-null  float64\n",
      " 18  Ti                      160000 non-null  float64\n",
      " 19  Ag                      160000 non-null  float64\n",
      " 20  Zr                      160000 non-null  float64\n",
      "dtypes: float64(11), int64(4), object(6)\n",
      "memory usage: 25.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   ID                      160000 non-null  int64  \n",
      " 1   alloy                   160000 non-null  object \n",
      " 2   cutTemp                 160000 non-null  object \n",
      " 3   rollTemp                160000 non-null  object \n",
      " 4   firstPassRollPressure   160000 non-null  int64  \n",
      " 5   secondPassRollPressure  160000 non-null  int64  \n",
      " 6   topEdgeMicroChipping    160000 non-null  object \n",
      " 7   blockSource             160000 non-null  object \n",
      " 8   machineRestart          160000 non-null  object \n",
      " 9   contourDefNdx           160000 non-null  int64  \n",
      " 10  clearPassNdx            160000 non-null  float64\n",
      " 11  y_passXtremeDurability  160000 non-null  int64  \n",
      " 12  Cu                      160000 non-null  float64\n",
      " 13  Mg                      160000 non-null  float64\n",
      " 14  Mn                      160000 non-null  float64\n",
      " 15  Si                      160000 non-null  float64\n",
      " 16  Zn                      160000 non-null  float64\n",
      " 17  Cr                      160000 non-null  float64\n",
      " 18  Fe                      160000 non-null  float64\n",
      " 19  Ti                      160000 non-null  float64\n",
      " 20  Ag                      160000 non-null  float64\n",
      " 21  Zr                      160000 non-null  float64\n",
      "dtypes: float64(11), int64(5), object(6)\n",
      "memory usage: 26.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "0:\tlearn: 0.6790796\ttest: 0.6791940\tbest: 0.6791940 (0)\ttotal: 138ms\tremaining: 6m 53s\n",
      "200:\tlearn: 0.4230294\ttest: 0.4330748\tbest: 0.4330748 (200)\ttotal: 8.91s\tremaining: 2m 4s\n",
      "400:\tlearn: 0.4147764\ttest: 0.4302714\tbest: 0.4302559 (394)\ttotal: 17.1s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.4082924\ttest: 0.4302811\tbest: 0.4300474 (520)\ttotal: 25.9s\tremaining: 1m 43s\n",
      "800:\tlearn: 0.4026065\ttest: 0.4304950\tbest: 0.4300474 (520)\ttotal: 34.8s\tremaining: 1m 35s\n",
      "1000:\tlearn: 0.3973703\ttest: 0.4310673\tbest: 0.4300474 (520)\ttotal: 43.7s\tremaining: 1m 27s\n",
      "1200:\tlearn: 0.3923364\ttest: 0.4317640\tbest: 0.4300474 (520)\ttotal: 52.6s\tremaining: 1m 18s\n",
      "1400:\tlearn: 0.3876160\ttest: 0.4324086\tbest: 0.4300474 (520)\ttotal: 1m 2s\tremaining: 1m 10s\n",
      "1600:\tlearn: 0.3827519\ttest: 0.4329412\tbest: 0.4300474 (520)\ttotal: 1m 10s\tremaining: 1m 2s\n",
      "1800:\tlearn: 0.3782314\ttest: 0.4334240\tbest: 0.4300474 (520)\ttotal: 1m 20s\tremaining: 53.6s\n",
      "2000:\tlearn: 0.3739311\ttest: 0.4341491\tbest: 0.4300474 (520)\ttotal: 1m 30s\tremaining: 45.2s\n",
      "2200:\tlearn: 0.3696760\ttest: 0.4349595\tbest: 0.4300474 (520)\ttotal: 1m 40s\tremaining: 36.4s\n",
      "2400:\tlearn: 0.3657247\ttest: 0.4355101\tbest: 0.4300474 (520)\ttotal: 1m 50s\tremaining: 27.5s\n",
      "2600:\tlearn: 0.3618791\ttest: 0.4361714\tbest: 0.4300474 (520)\ttotal: 1m 59s\tremaining: 18.4s\n",
      "2800:\tlearn: 0.3580227\ttest: 0.4368035\tbest: 0.4300474 (520)\ttotal: 2m 9s\tremaining: 9.19s\n",
      "2999:\tlearn: 0.3542617\ttest: 0.4375321\tbest: 0.4300474 (520)\ttotal: 2m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4300474281\n",
      "bestIteration = 520\n",
      "\n",
      "Shrink model to first 521 iterations.\n",
      "Fold 1 LogLoss = 0.43005\n",
      "\n",
      "===== Fold 2 =====\n",
      "0:\tlearn: 0.6769880\ttest: 0.6771265\tbest: 0.6771265 (0)\ttotal: 59ms\tremaining: 2m 56s\n",
      "200:\tlearn: 0.4235833\ttest: 0.4304443\tbest: 0.4304443 (200)\ttotal: 8.86s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.4151902\ttest: 0.4274707\tbest: 0.4274707 (400)\ttotal: 17.6s\tremaining: 1m 53s\n",
      "600:\tlearn: 0.4086266\ttest: 0.4275494\tbest: 0.4272630 (477)\ttotal: 26.9s\tremaining: 1m 47s\n",
      "800:\tlearn: 0.4029575\ttest: 0.4281117\tbest: 0.4272630 (477)\ttotal: 36.1s\tremaining: 1m 39s\n",
      "1000:\tlearn: 0.3976010\ttest: 0.4287893\tbest: 0.4272630 (477)\ttotal: 45.5s\tremaining: 1m 30s\n",
      "1200:\tlearn: 0.3925035\ttest: 0.4295505\tbest: 0.4272630 (477)\ttotal: 54.9s\tremaining: 1m 22s\n",
      "1400:\tlearn: 0.3875955\ttest: 0.4302307\tbest: 0.4272630 (477)\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "1600:\tlearn: 0.3829636\ttest: 0.4308866\tbest: 0.4272630 (477)\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "1800:\tlearn: 0.3784669\ttest: 0.4316380\tbest: 0.4272630 (477)\ttotal: 1m 23s\tremaining: 55.3s\n",
      "2000:\tlearn: 0.3741605\ttest: 0.4323636\tbest: 0.4272630 (477)\ttotal: 1m 32s\tremaining: 46.2s\n",
      "2200:\tlearn: 0.3701038\ttest: 0.4330279\tbest: 0.4272630 (477)\ttotal: 1m 42s\tremaining: 37s\n",
      "2400:\tlearn: 0.3660665\ttest: 0.4338239\tbest: 0.4272630 (477)\ttotal: 1m 51s\tremaining: 27.8s\n",
      "2600:\tlearn: 0.3620109\ttest: 0.4346409\tbest: 0.4272630 (477)\ttotal: 2m\tremaining: 18.5s\n",
      "2800:\tlearn: 0.3582133\ttest: 0.4353959\tbest: 0.4272630 (477)\ttotal: 2m 10s\tremaining: 9.26s\n",
      "2999:\tlearn: 0.3545198\ttest: 0.4361694\tbest: 0.4272630 (477)\ttotal: 2m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4272629671\n",
      "bestIteration = 477\n",
      "\n",
      "Shrink model to first 478 iterations.\n",
      "Fold 2 LogLoss = 0.42726\n",
      "\n",
      "===== Fold 3 =====\n",
      "0:\tlearn: 0.6791834\ttest: 0.6792463\tbest: 0.6792463 (0)\ttotal: 50ms\tremaining: 2m 29s\n",
      "200:\tlearn: 0.4232882\ttest: 0.4328775\tbest: 0.4328775 (200)\ttotal: 8.87s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.4147883\ttest: 0.4292999\tbest: 0.4292999 (400)\ttotal: 17.8s\tremaining: 1m 55s\n",
      "600:\tlearn: 0.4081571\ttest: 0.4288864\tbest: 0.4288138 (529)\ttotal: 27.5s\tremaining: 1m 49s\n",
      "800:\tlearn: 0.4020430\ttest: 0.4291578\tbest: 0.4288138 (529)\ttotal: 37s\tremaining: 1m 41s\n",
      "1000:\tlearn: 0.3966658\ttest: 0.4297119\tbest: 0.4288138 (529)\ttotal: 46.4s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.3915014\ttest: 0.4302634\tbest: 0.4288138 (529)\ttotal: 55.9s\tremaining: 1m 23s\n",
      "1400:\tlearn: 0.3867968\ttest: 0.4309407\tbest: 0.4288138 (529)\ttotal: 1m 5s\tremaining: 1m 14s\n",
      "1600:\tlearn: 0.3822410\ttest: 0.4315690\tbest: 0.4288138 (529)\ttotal: 1m 14s\tremaining: 1m 5s\n",
      "1800:\tlearn: 0.3776847\ttest: 0.4323148\tbest: 0.4288138 (529)\ttotal: 1m 24s\tremaining: 56.2s\n",
      "2000:\tlearn: 0.3733733\ttest: 0.4329405\tbest: 0.4288138 (529)\ttotal: 1m 33s\tremaining: 46.9s\n",
      "2200:\tlearn: 0.3691302\ttest: 0.4335165\tbest: 0.4288138 (529)\ttotal: 1m 43s\tremaining: 37.6s\n",
      "2400:\tlearn: 0.3650284\ttest: 0.4341399\tbest: 0.4288138 (529)\ttotal: 1m 53s\tremaining: 28.3s\n",
      "2600:\tlearn: 0.3609106\ttest: 0.4348151\tbest: 0.4288138 (529)\ttotal: 2m 2s\tremaining: 18.8s\n",
      "2800:\tlearn: 0.3569646\ttest: 0.4355869\tbest: 0.4288138 (529)\ttotal: 2m 12s\tremaining: 9.4s\n",
      "2999:\tlearn: 0.3530978\ttest: 0.4362167\tbest: 0.4288138 (529)\ttotal: 2m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4288137657\n",
      "bestIteration = 529\n",
      "\n",
      "Shrink model to first 530 iterations.\n",
      "Fold 3 LogLoss = 0.42881\n",
      "\n",
      "===== Fold 4 =====\n",
      "0:\tlearn: 0.6771778\ttest: 0.6769835\tbest: 0.6769835 (0)\ttotal: 48.2ms\tremaining: 2m 24s\n",
      "200:\tlearn: 0.4262344\ttest: 0.4236969\tbest: 0.4236969 (200)\ttotal: 8.88s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.4178121\ttest: 0.4192159\tbest: 0.4192159 (400)\ttotal: 17.7s\tremaining: 1m 54s\n",
      "600:\tlearn: 0.4117295\ttest: 0.4186620\tbest: 0.4186526 (597)\ttotal: 27s\tremaining: 1m 47s\n",
      "800:\tlearn: 0.4060812\ttest: 0.4186792\tbest: 0.4185544 (701)\ttotal: 36.5s\tremaining: 1m 40s\n",
      "1000:\tlearn: 0.4009031\ttest: 0.4190522\tbest: 0.4185544 (701)\ttotal: 45.9s\tremaining: 1m 31s\n",
      "1200:\tlearn: 0.3960325\ttest: 0.4193443\tbest: 0.4185544 (701)\ttotal: 55.5s\tremaining: 1m 23s\n",
      "1400:\tlearn: 0.3912375\ttest: 0.4198924\tbest: 0.4185544 (701)\ttotal: 1m 5s\tremaining: 1m 14s\n",
      "1600:\tlearn: 0.3868326\ttest: 0.4204019\tbest: 0.4185544 (701)\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "1800:\tlearn: 0.3826159\ttest: 0.4210720\tbest: 0.4185544 (701)\ttotal: 1m 25s\tremaining: 56.7s\n",
      "2000:\tlearn: 0.3784407\ttest: 0.4216513\tbest: 0.4185544 (701)\ttotal: 1m 35s\tremaining: 47.4s\n",
      "2200:\tlearn: 0.3744388\ttest: 0.4222859\tbest: 0.4185544 (701)\ttotal: 1m 44s\tremaining: 38s\n",
      "2400:\tlearn: 0.3705594\ttest: 0.4228699\tbest: 0.4185544 (701)\ttotal: 1m 54s\tremaining: 28.5s\n",
      "2600:\tlearn: 0.3668224\ttest: 0.4234410\tbest: 0.4185544 (701)\ttotal: 2m 3s\tremaining: 19s\n",
      "2800:\tlearn: 0.3630608\ttest: 0.4241620\tbest: 0.4185544 (701)\ttotal: 2m 13s\tremaining: 9.46s\n",
      "2999:\tlearn: 0.3594628\ttest: 0.4248420\tbest: 0.4185544 (701)\ttotal: 2m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4185544201\n",
      "bestIteration = 701\n",
      "\n",
      "Shrink model to first 702 iterations.\n",
      "Fold 4 LogLoss = 0.41855\n",
      "\n",
      "===== Fold 5 =====\n",
      "0:\tlearn: 0.6779122\ttest: 0.6779311\tbest: 0.6779311 (0)\ttotal: 49.3ms\tremaining: 2m 27s\n",
      "200:\tlearn: 0.4249625\ttest: 0.4262597\tbest: 0.4262597 (200)\ttotal: 9.01s\tremaining: 2m 5s\n",
      "400:\tlearn: 0.4165257\ttest: 0.4222879\tbest: 0.4222879 (400)\ttotal: 17.8s\tremaining: 1m 55s\n",
      "600:\tlearn: 0.4099945\ttest: 0.4217973\tbest: 0.4217214 (519)\ttotal: 27.3s\tremaining: 1m 48s\n",
      "800:\tlearn: 0.4042836\ttest: 0.4219385\tbest: 0.4217214 (519)\ttotal: 36.8s\tremaining: 1m 41s\n",
      "1000:\tlearn: 0.3989013\ttest: 0.4224216\tbest: 0.4217214 (519)\ttotal: 46.4s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.3938426\ttest: 0.4229208\tbest: 0.4217214 (519)\ttotal: 56s\tremaining: 1m 23s\n",
      "1400:\tlearn: 0.3889589\ttest: 0.4236565\tbest: 0.4217214 (519)\ttotal: 1m 5s\tremaining: 1m 14s\n",
      "1600:\tlearn: 0.3843927\ttest: 0.4243239\tbest: 0.4217214 (519)\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "1800:\tlearn: 0.3800256\ttest: 0.4249580\tbest: 0.4217214 (519)\ttotal: 1m 24s\tremaining: 56.3s\n",
      "2000:\tlearn: 0.3756793\ttest: 0.4257380\tbest: 0.4217214 (519)\ttotal: 1m 34s\tremaining: 47.1s\n",
      "2200:\tlearn: 0.3715703\ttest: 0.4265041\tbest: 0.4217214 (519)\ttotal: 1m 43s\tremaining: 37.7s\n",
      "2400:\tlearn: 0.3675843\ttest: 0.4271644\tbest: 0.4217214 (519)\ttotal: 1m 53s\tremaining: 28.4s\n",
      "2600:\tlearn: 0.3635361\ttest: 0.4278874\tbest: 0.4217214 (519)\ttotal: 2m 3s\tremaining: 18.9s\n",
      "2800:\tlearn: 0.3596888\ttest: 0.4284526\tbest: 0.4217214 (519)\ttotal: 2m 13s\tremaining: 9.46s\n",
      "2999:\tlearn: 0.3560855\ttest: 0.4290886\tbest: 0.4217214 (519)\ttotal: 2m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4217213669\n",
      "bestIteration = 519\n",
      "\n",
      "Shrink model to first 520 iterations.\n",
      "Fold 5 LogLoss = 0.42172\n",
      "\n",
      "===== CatBoost CV Results =====\n",
      "Fold LogLosses: [0.43004742806070634, 0.4272629671342843, 0.4288137656607166, 0.41855442005642657, 0.4217213668887161]\n",
      "Mean LogLoss: 0.42527998956017\n",
      "StdDev: 0.0044055720153482955\n",
      "0:\tlearn: 0.6782105\ttotal: 85.3ms\tremaining: 4m 15s\n",
      "200:\tlearn: 0.4247779\ttotal: 11.3s\tremaining: 2m 36s\n",
      "400:\tlearn: 0.4176914\ttotal: 22s\tremaining: 2m 22s\n",
      "600:\tlearn: 0.4126930\ttotal: 33.1s\tremaining: 2m 12s\n",
      "800:\tlearn: 0.4080979\ttotal: 44.5s\tremaining: 2m 2s\n",
      "1000:\tlearn: 0.4039406\ttotal: 55.8s\tremaining: 1m 51s\n",
      "1200:\tlearn: 0.3999430\ttotal: 1m 6s\tremaining: 1m 40s\n",
      "1400:\tlearn: 0.3962188\ttotal: 1m 18s\tremaining: 1m 29s\n",
      "1600:\tlearn: 0.3924997\ttotal: 1m 29s\tremaining: 1m 17s\n",
      "1800:\tlearn: 0.3889553\ttotal: 1m 40s\tremaining: 1m 6s\n",
      "2000:\tlearn: 0.3854197\ttotal: 1m 51s\tremaining: 55.8s\n",
      "2200:\tlearn: 0.3820885\ttotal: 2m 3s\tremaining: 44.7s\n",
      "2400:\tlearn: 0.3790762\ttotal: 2m 14s\tremaining: 33.6s\n",
      "2600:\tlearn: 0.3758633\ttotal: 2m 26s\tremaining: 22.4s\n",
      "2800:\tlearn: 0.3727524\ttotal: 2m 37s\tremaining: 11.2s\n",
      "2999:\tlearn: 0.3698874\ttotal: 2m 49s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x11247eb40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# -------------------------\n",
    "# Identify features\n",
    "# -------------------------\n",
    "\n",
    "target = \"y_passXtremeDurability\"\n",
    "\n",
    "categorical_cols = [\n",
    "    \"alloy\",\n",
    "    \"cutTemp\",\n",
    "    \"rollTemp\",\n",
    "    \"topEdgeMicroChipping\",\n",
    "    \"blockSource\",\n",
    "    \"machineRestart\"\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"firstPassRollPressure\",\n",
    "    \"secondPassRollPressure\",\n",
    "    \"contourDefNdx\",\n",
    "    \"clearPassNdx\",\n",
    "    \"Cu\",\"Mg\",\"Mn\",\"Si\",\"Zn\",\"Cr\",\"Fe\",\"Ti\",\"Ag\",\"Zr\"\n",
    "]\n",
    "\n",
    "features = categorical_cols + numeric_cols\n",
    "\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "\n",
    "test_X = test[features]\n",
    "\n",
    "# -------------------------\n",
    "# CatBoost Model Settings\n",
    "# -------------------------\n",
    "\n",
    "cat_model_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Logloss\",\n",
    "    \"random_seed\": 42,\n",
    "    \"iterations\": 3000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"depth\": 8,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"bagging_temperature\": 1,\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"verbose\": 200\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# K-Fold CV\n",
    "# -------------------------\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_pred = np.zeros(len(train))\n",
    "fold_losses = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X), 1):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features=categorical_cols)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categorical_cols)\n",
    "\n",
    "    model = CatBoostClassifier(**cat_model_params)\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "    # Predict probability of class 1\n",
    "    val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "\n",
    "    # Log loss for this fold\n",
    "    loss = log_loss(y_val, val_pred)\n",
    "    fold_losses.append(loss)\n",
    "    print(f\"Fold {fold} LogLoss = {loss:.5f}\")\n",
    "\n",
    "    # Store OOF predictions\n",
    "    oof_pred[valid_idx] = val_pred\n",
    "\n",
    "# -------------------------\n",
    "# Overall CV Performance\n",
    "# -------------------------\n",
    "\n",
    "print(\"\\n===== CatBoost CV Results =====\")\n",
    "print(\"Fold LogLosses:\", fold_losses)\n",
    "print(\"Mean LogLoss:\", np.mean(fold_losses))\n",
    "print(\"StdDev:\", np.std(fold_losses))\n",
    "\n",
    "# -------------------------\n",
    "# Train final model on full data\n",
    "# -------------------------\n",
    "\n",
    "full_pool = Pool(X, y, cat_features=categorical_cols)\n",
    "final_model = CatBoostClassifier(**cat_model_params)\n",
    "final_model.fit(full_pool, verbose=200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_catboost.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Test set predictions\n",
    "# -------------------------\n",
    "\n",
    "test_pool = Pool(test_X, cat_features=categorical_cols)\n",
    "test_pred = final_model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"ID\"],\n",
    "    \"y_passXtremeDurability\": test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_catboost.csv\", index=False)\n",
    "print(\"Saved submission_catboost.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 11:41:09,623] A new study created in memory with name: no-name-2877643a-445d-4644-bac4-679ca7671d0a\n",
      "[I 2025-11-28 11:43:47,161] Trial 0 finished with value: 0.4239247188465523 and parameters: {'learning_rate': 0.048005750653714645, 'depth': 6, 'l2_leaf_reg': 3.230836366495558, 'random_strength': 4.208508416515103, 'border_count': 227, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4057120085882898}. Best is trial 0 with value: 0.4239247188465523.\n",
      "[I 2025-11-28 11:51:47,362] Trial 1 finished with value: 0.4257792653953011 and parameters: {'learning_rate': 0.019457905977363302, 'depth': 10, 'l2_leaf_reg': 1.0426508318286716, 'random_strength': 1.5938452630299549, 'border_count': 207, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9873706067290364}. Best is trial 0 with value: 0.4239247188465523.\n",
      "[I 2025-11-28 11:54:49,742] Trial 2 finished with value: 0.4237145044394953 and parameters: {'learning_rate': 0.0457663924533457, 'depth': 5, 'l2_leaf_reg': 5.350196121005697, 'random_strength': 4.212392824501671, 'border_count': 139, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.613259563045595}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:02:42,733] Trial 3 finished with value: 0.42414511598730764 and parameters: {'learning_rate': 0.012103783646493197, 'depth': 6, 'l2_leaf_reg': 2.0211680209551646, 'random_strength': 0.5289838116908585, 'border_count': 130, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.8997860244461386}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:04:26,240] Trial 4 finished with value: 0.4240150324054525 and parameters: {'learning_rate': 0.086010684240937, 'depth': 6, 'l2_leaf_reg': 1.110697049573721, 'random_strength': 2.221771519814619, 'border_count': 193, 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:06:51,309] Trial 5 finished with value: 0.4302129214991341 and parameters: {'learning_rate': 0.07021083885451211, 'depth': 10, 'l2_leaf_reg': 4.85042261959816, 'random_strength': 4.009509993780319, 'border_count': 227, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.8240171425466514}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:11:00,895] Trial 6 finished with value: 0.4253166153019146 and parameters: {'learning_rate': 0.03135992075833238, 'depth': 10, 'l2_leaf_reg': 1.5307343517873238, 'random_strength': 3.557108118390432, 'border_count': 178, 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:13:32,246] Trial 7 finished with value: 0.42678869857413293 and parameters: {'learning_rate': 0.041952665757460775, 'depth': 10, 'l2_leaf_reg': 1.5971569546737627, 'random_strength': 0.8322429572751239, 'border_count': 89, 'bootstrap_type': 'Bernoulli', 'subsample': 0.671194726411486}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:14:56,459] Trial 8 finished with value: 0.4249756260260157 and parameters: {'learning_rate': 0.11635749081469769, 'depth': 8, 'l2_leaf_reg': 1.2154439729890052, 'random_strength': 0.9254544108259927, 'border_count': 76, 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:16:37,385] Trial 9 finished with value: 0.4246985377458291 and parameters: {'learning_rate': 0.10728304521577749, 'depth': 8, 'l2_leaf_reg': 5.009232159331382, 'random_strength': 4.287382407370387, 'border_count': 255, 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:19:35,911] Trial 10 finished with value: 0.42653363876433287 and parameters: {'learning_rate': 0.16482337663268648, 'depth': 4, 'l2_leaf_reg': 9.738754334194933, 'random_strength': 4.943061913703415, 'border_count': 34, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.260805205833032}. Best is trial 2 with value: 0.4237145044394953.\n",
      "[I 2025-11-28 12:22:58,827] Trial 11 finished with value: 0.42344609050982107 and parameters: {'learning_rate': 0.05160866875760279, 'depth': 4, 'l2_leaf_reg': 3.61016777833069, 'random_strength': 2.838580404393465, 'border_count': 148, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.1598689013819204}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 12:29:08,629] Trial 12 finished with value: 0.42350705026150504 and parameters: {'learning_rate': 0.027676727706132245, 'depth': 4, 'l2_leaf_reg': 5.637176004322502, 'random_strength': 3.03318266484204, 'border_count': 138, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.14932744200504222}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 12:36:36,760] Trial 13 finished with value: 0.42424011544897455 and parameters: {'learning_rate': 0.025142431159638483, 'depth': 4, 'l2_leaf_reg': 8.158157922886856, 'random_strength': 2.9073073516001324, 'border_count': 164, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.6422370938615047}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 12:43:44,261] Trial 14 finished with value: 0.4235618266638001 and parameters: {'learning_rate': 0.013909687854040734, 'depth': 4, 'l2_leaf_reg': 2.94693647498915, 'random_strength': 2.7697651773051906, 'border_count': 109, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.02520296337691097}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 12:47:08,258] Trial 15 finished with value: 0.42490019915006166 and parameters: {'learning_rate': 0.06399286005033299, 'depth': 5, 'l2_leaf_reg': 3.3423096315354566, 'random_strength': 2.027021743816137, 'border_count': 151, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.0638706882982385}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 12:52:29,721] Trial 16 finished with value: 0.42381970663562407 and parameters: {'learning_rate': 0.02028313788706917, 'depth': 5, 'l2_leaf_reg': 7.040657762314941, 'random_strength': 3.164586594310258, 'border_count': 115, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5033303247156593}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 12:56:59,855] Trial 17 finished with value: 0.4273290588659576 and parameters: {'learning_rate': 0.030346425610364065, 'depth': 7, 'l2_leaf_reg': 3.859208209128605, 'random_strength': 1.680293983691631, 'border_count': 64, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.492958813299987}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:04:39,833] Trial 18 finished with value: 0.4239690105602345 and parameters: {'learning_rate': 0.016768929919764378, 'depth': 4, 'l2_leaf_reg': 2.2973534723743048, 'random_strength': 3.5771210951415564, 'border_count': 164, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.2197924595927887}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:08:37,007] Trial 19 finished with value: 0.42362547499153785 and parameters: {'learning_rate': 0.035179566804897706, 'depth': 5, 'l2_leaf_reg': 6.155043301406608, 'random_strength': 2.4475478078752957, 'border_count': 105, 'bootstrap_type': 'Bernoulli', 'subsample': 0.994898673825509}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:11:03,308] Trial 20 finished with value: 0.4264030151175314 and parameters: {'learning_rate': 0.05833416665240008, 'depth': 7, 'l2_leaf_reg': 4.00488282275536, 'random_strength': 0.030812578171985905, 'border_count': 132, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.6471877443265694}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:18:37,937] Trial 21 finished with value: 0.4238532133669176 and parameters: {'learning_rate': 0.010884374408511267, 'depth': 4, 'l2_leaf_reg': 2.5069707060160296, 'random_strength': 2.956138557705714, 'border_count': 104, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.027317563245600814}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:26:14,821] Trial 22 finished with value: 0.42357177233762433 and parameters: {'learning_rate': 0.01519606330828175, 'depth': 4, 'l2_leaf_reg': 2.6172914092001616, 'random_strength': 2.6866810667708827, 'border_count': 117, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.09717939431339231}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:32:22,407] Trial 23 finished with value: 0.42401371488821366 and parameters: {'learning_rate': 0.02408756610667844, 'depth': 5, 'l2_leaf_reg': 4.088744664920968, 'random_strength': 3.5170771811585153, 'border_count': 147, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.2174008365734317}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:39:52,901] Trial 24 finished with value: 0.423557194462875 and parameters: {'learning_rate': 0.013565948472134721, 'depth': 4, 'l2_leaf_reg': 2.9052968064735185, 'random_strength': 1.8948559132691467, 'border_count': 61, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.05835891905576565}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:44:40,559] Trial 25 finished with value: 0.42402249593565966 and parameters: {'learning_rate': 0.022932077865493134, 'depth': 6, 'l2_leaf_reg': 1.9683543511788206, 'random_strength': 1.6793116999299773, 'border_count': 59, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6847150510359976}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:48:52,876] Trial 26 finished with value: 0.4242779371516236 and parameters: {'learning_rate': 0.03739552525849195, 'depth': 5, 'l2_leaf_reg': 6.159031451932277, 'random_strength': 2.12679831741832, 'border_count': 46, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.5253900181240159}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:56:12,596] Trial 27 finished with value: 0.43278090172062117 and parameters: {'learning_rate': 0.010477641161589262, 'depth': 4, 'l2_leaf_reg': 4.364424816256299, 'random_strength': 1.3282893932917212, 'border_count': 87, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.965415265897631}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 13:59:59,951] Trial 28 finished with value: 0.42507828941796194 and parameters: {'learning_rate': 0.026985844883164738, 'depth': 9, 'l2_leaf_reg': 5.852324498796158, 'random_strength': 3.2252612615492993, 'border_count': 185, 'bootstrap_type': 'Bernoulli', 'subsample': 0.77261612227601}. Best is trial 11 with value: 0.42344609050982107.\n",
      "[I 2025-11-28 14:02:26,813] Trial 29 finished with value: 0.4238703580388797 and parameters: {'learning_rate': 0.04995030429390476, 'depth': 6, 'l2_leaf_reg': 3.3285756351756812, 'random_strength': 2.4778883044004347, 'border_count': 209, 'bootstrap_type': 'MVS'}. Best is trial 11 with value: 0.42344609050982107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogLoss: 0.42344609050982107\n",
      "Best Params: {'learning_rate': 0.05160866875760279, 'depth': 4, 'l2_leaf_reg': 3.61016777833069, 'random_strength': 2.838580404393465, 'border_count': 148, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.1598689013819204}\n",
      "0:\tlearn: 0.6738835\ttotal: 32.5ms\tremaining: 1m 37s\n",
      "200:\tlearn: 0.4361478\ttotal: 6.28s\tremaining: 1m 27s\n",
      "400:\tlearn: 0.4244302\ttotal: 12.7s\tremaining: 1m 22s\n",
      "600:\tlearn: 0.4222583\ttotal: 19.4s\tremaining: 1m 17s\n",
      "800:\tlearn: 0.4212344\ttotal: 26.2s\tremaining: 1m 11s\n",
      "1000:\tlearn: 0.4204892\ttotal: 32.9s\tremaining: 1m 5s\n",
      "1200:\tlearn: 0.4198466\ttotal: 39.7s\tremaining: 59.4s\n",
      "1400:\tlearn: 0.4192226\ttotal: 46.5s\tremaining: 53.1s\n",
      "1600:\tlearn: 0.4185725\ttotal: 53.4s\tremaining: 46.7s\n",
      "1800:\tlearn: 0.4179942\ttotal: 1m\tremaining: 40.2s\n",
      "2000:\tlearn: 0.4174657\ttotal: 1m 7s\tremaining: 33.6s\n",
      "2200:\tlearn: 0.4169293\ttotal: 1m 14s\tremaining: 27s\n",
      "2400:\tlearn: 0.4164808\ttotal: 1m 21s\tremaining: 20.3s\n",
      "2600:\tlearn: 0.4160194\ttotal: 1m 28s\tremaining: 13.5s\n",
      "2800:\tlearn: 0.4155484\ttotal: 1m 35s\tremaining: 6.79s\n",
      "2999:\tlearn: 0.4151218\ttotal: 1m 42s\tremaining: 0us\n",
      "Saved submission_catboost_optuna.csv\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# -------------------------\n",
    "# Data setup\n",
    "# -------------------------\n",
    "\n",
    "target = \"y_passXtremeDurability\"\n",
    "\n",
    "categorical_cols = [\n",
    "    \"alloy\",\n",
    "    \"cutTemp\",\n",
    "    \"rollTemp\",\n",
    "    \"topEdgeMicroChipping\",\n",
    "    \"blockSource\",\n",
    "    \"machineRestart\",\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"firstPassRollPressure\",\n",
    "    \"secondPassRollPressure\",\n",
    "    \"contourDefNdx\",\n",
    "    \"clearPassNdx\",\n",
    "    \"Cu\",\"Mg\",\"Mn\",\"Si\",\"Zn\",\"Cr\",\"Fe\",\"Ti\",\"Ag\",\"Zr\"\n",
    "]\n",
    "\n",
    "features = categorical_cols + numeric_cols\n",
    "\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "\n",
    "test_X = test[features]\n",
    "\n",
    "# -------------------------\n",
    "# Optuna objective\n",
    "# -------------------------\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter search space\n",
    "    params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Logloss\",\n",
    "    \"random_seed\": 42,\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"verbose\": False,\n",
    "    \"iterations\": 3000,\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "    \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "    \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0, log=True),\n",
    "    \"random_strength\": trial.suggest_float(\"random_strength\", 0.0, 5.0),\n",
    "    \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "    \"bootstrap_type\": trial.suggest_categorical(\n",
    "        \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "    ),\n",
    "}\n",
    "\n",
    "    # Only valid for Bayesian\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.0, 5.0)\n",
    "\n",
    "    # Only valid for Bernoulli\n",
    "    if params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_losses = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        train_pool = Pool(X_train, y_train, cat_features=categorical_cols)\n",
    "        val_pool = Pool(X_val, y_val, cat_features=categorical_cols)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(\n",
    "            train_pool,\n",
    "            eval_set=val_pool,\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=200,\n",
    "        )\n",
    "\n",
    "        val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "        loss = log_loss(y_val, val_pred)\n",
    "        fold_losses.append(loss)\n",
    "\n",
    "    mean_loss = float(np.mean(fold_losses))\n",
    "    return mean_loss\n",
    "\n",
    "# -------------------------\n",
    "# Run Optuna study\n",
    "# -------------------------\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)  # bump n_trials up if you have compute\n",
    "\n",
    "print(\"Best LogLoss:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "# Add fixed params that we didn't tune\n",
    "best_params.update({\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Logloss\",\n",
    "    \"random_seed\": 42,\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"iterations\": 3000,\n",
    "    \"verbose\": 200\n",
    "})\n",
    "\n",
    "# -------------------------\n",
    "# Train final model on full data\n",
    "# -------------------------\n",
    "\n",
    "full_pool = Pool(X, y, cat_features=categorical_cols)\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(\n",
    "    full_pool,\n",
    "    eval_set=None,  # you could hold out a small validation set if you want\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Predict on test set\n",
    "# -------------------------\n",
    "\n",
    "test_pool = Pool(test_X, cat_features=categorical_cols)\n",
    "test_pred = final_model.predict_proba(test_pool)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"ID\"],\n",
    "    \"y_passXtremeDurability\": test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_catboost_optuna.csv\", index=False)\n",
    "print(\"Saved submission_catboost_optuna.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 trial scores:\n",
      "11 0.42344609050982107\n",
      "12 0.42350705026150504\n",
      "24 0.423557194462875\n",
      "14 0.4235618266638001\n",
      "22 0.42357177233762433\n",
      "19 0.42362547499153785\n",
      "2 0.4237145044394953\n",
      "16 0.42381970663562407\n",
      "21 0.4238532133669176\n",
      "29 0.4238703580388797\n"
     ]
    }
   ],
   "source": [
    "# Get best 10 trials\n",
    "top_trials = sorted(study.trials, key=lambda t: t.value)[:10]\n",
    "\n",
    "print(\"Top 10 trial scores:\")\n",
    "for t in top_trials:\n",
    "    print(t.number, t.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 10 models from top Optuna trials.\n"
     ]
    }
   ],
   "source": [
    "# Base fixed params\n",
    "base_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Logloss\",\n",
    "    \"iterations\": 3000,\n",
    "    \"random_seed\": 42,\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "models = []\n",
    "\n",
    "for trial in top_trials:\n",
    "    params = trial.params.copy()\n",
    "    params.update(base_params)\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(Pool(X, y, cat_features=categorical_cols))\n",
    "    models.append(model)\n",
    "\n",
    "print(f\"Trained {len(models)} models from top Optuna trials.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['ID', 'alloy', 'cutTemp', 'rollTemp', 'firstPassRollPressure', 'secondPassRollPressure', 'topEdgeMicroChipping', 'blockSource', 'machineRestart', 'contourDefNdx', 'clearPassNdx', 'Cu', 'Mg', 'Mn', 'Si', 'Zn', 'Cr', 'Fe', 'Ti', 'Ag', 'Zr']\n",
      "Test_X columns: ['alloy', 'cutTemp', 'rollTemp', 'topEdgeMicroChipping', 'blockSource', 'machineRestart', 'firstPassRollPressure', 'secondPassRollPressure', 'contourDefNdx', 'clearPassNdx', 'Cu', 'Mg', 'Mn', 'Si', 'Zn', 'Cr', 'Fe', 'Ti', 'Ag', 'Zr']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train columns:\", list(X.columns))\n",
    "print(\"Test_X columns:\", list(test_X.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_with_ID = pd.concat([test[\"ID\"], test[features]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool = Pool(test_X_with_ID, cat_features=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for model in models:\n",
    "    p = model.predict_proba(test_pool)[:, 1]\n",
    "    all_preds.append(p)\n",
    "\n",
    "ensemble_pred = np.mean(np.column_stack(all_preds), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_top10_optuna_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"ID\"],\n",
    "    \"y_passXtremeDurability\": ensemble_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_top10_optuna_ensemble.csv\", index=False)\n",
    "print(\"Saved submission_top10_optuna_ensemble.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
