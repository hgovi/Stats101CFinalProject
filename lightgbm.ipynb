{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "test = pd.read_csv(\"data/aluminum_coldRoll_testNoY.csv\")\n",
    "train = pd.read_csv(\"data/aluminum_coldRoll_train.csv\")\n",
    "alloy = pd.read_csv(\"data/ally.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure alloy column is string (important!)\n",
    "train[\"alloy\"] = train[\"alloy\"].astype(str)\n",
    "test[\"alloy\"] = test[\"alloy\"].astype(str)\n",
    "alloy[\"alloy\"] = alloy[\"alloy\"].astype(str)\n",
    "\n",
    "# Merge the composition columns into train/test\n",
    "train = train.merge(alloy, on=\"alloy\", how=\"left\")\n",
    "test = test.merge(alloy, on=\"alloy\", how=\"left\")\n",
    "test_ids = test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   ID                      160000 non-null  int64  \n",
      " 1   alloy                   160000 non-null  object \n",
      " 2   cutTemp                 160000 non-null  object \n",
      " 3   rollTemp                160000 non-null  object \n",
      " 4   firstPassRollPressure   160000 non-null  int64  \n",
      " 5   secondPassRollPressure  160000 non-null  int64  \n",
      " 6   topEdgeMicroChipping    160000 non-null  object \n",
      " 7   blockSource             160000 non-null  object \n",
      " 8   machineRestart          160000 non-null  object \n",
      " 9   contourDefNdx           160000 non-null  int64  \n",
      " 10  clearPassNdx            160000 non-null  float64\n",
      " 11  y_passXtremeDurability  160000 non-null  int64  \n",
      " 12  Cu                      160000 non-null  float64\n",
      " 13  Mg                      160000 non-null  float64\n",
      " 14  Mn                      160000 non-null  float64\n",
      " 15  Si                      160000 non-null  float64\n",
      " 16  Zn                      160000 non-null  float64\n",
      " 17  Cr                      160000 non-null  float64\n",
      " 18  Fe                      160000 non-null  float64\n",
      " 19  Ti                      160000 non-null  float64\n",
      " 20  Ag                      160000 non-null  float64\n",
      " 21  Zr                      160000 non-null  float64\n",
      "dtypes: float64(11), int64(5), object(6)\n",
      "memory usage: 26.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== FOLD 1 ====================\n",
      "Fold 1 LogLoss = 0.44789\n",
      "\n",
      "==================== FOLD 2 ====================\n",
      "Fold 2 LogLoss = 0.44810\n",
      "\n",
      "==================== FOLD 3 ====================\n",
      "Fold 3 LogLoss = 0.44406\n",
      "\n",
      "==================== FOLD 4 ====================\n",
      "Fold 4 LogLoss = 0.44989\n",
      "\n",
      "==================== FOLD 5 ====================\n",
      "Fold 5 LogLoss = 0.44817\n",
      "\n",
      "==================== LIGHTGBM 5-FOLD RESULTS ====================\n",
      "Fold LogLoss: [0.4478901439376981, 0.4480969221955147, 0.44406000485417335, 0.449891202244508, 0.4481741252794832]\n",
      "Mean LogLoss: 0.4476224797022755\n",
      "StdDev: 0.001920384424127764\n",
      "\n",
      "OOF predictions added to df as column 'oof_pred'\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. PREP DATA\n",
    "# =========================================================\n",
    "\n",
    "df = train.copy()\n",
    "\n",
    "target = \"y_passXtremeDurability\"\n",
    "categorical_cols = [\"alloy\", \"cutTemp\", \"rollTemp\",\n",
    "                    \"topEdgeMicroChipping\", \"blockSource\", \"machineRestart\"]\n",
    "\n",
    "# Label encode categoricals\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "\n",
    "X = df.drop(columns=[target, \"ID\"])\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. LIGHTGBM PARAMS\n",
    "# =========================================================\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 64,\n",
    "    \"max_depth\": -1,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 3,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"cat_l2\": 10,\n",
    "    \"cat_smooth\": 10,\n",
    "    \"seed\": 42,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. STRATIFIED 5-FOLD CV\n",
    "# =========================================================\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_pred = np.zeros(len(df))\n",
    "fold_losses = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n==================== FOLD {fold+1} ====================\")\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train,\n",
    "        label=y_train,\n",
    "        categorical_feature=categorical_cols\n",
    "    )\n",
    "\n",
    "    valid_data = lgb.Dataset(\n",
    "        X_valid,\n",
    "        label=y_valid,\n",
    "        categorical_feature=categorical_cols\n",
    "    )\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.log_evaluation(period=200)]\n",
    "    )\n",
    "\n",
    "    # Predict on validation fold\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    oof_pred[valid_idx] = valid_pred\n",
    "\n",
    "    # Compute fold log loss\n",
    "    fold_loss = log_loss(y_valid, valid_pred)\n",
    "    fold_losses.append(fold_loss)\n",
    "    print(f\"Fold {fold+1} LogLoss = {fold_loss:.5f}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. RESULTS\n",
    "# =========================================================\n",
    "\n",
    "print(\"\\n==================== LIGHTGBM 5-FOLD RESULTS ====================\")\n",
    "print(\"Fold LogLoss:\", fold_losses)\n",
    "print(\"Mean LogLoss:\", np.mean(fold_losses))\n",
    "print(\"StdDev:\", np.std(fold_losses))\n",
    "\n",
    "\n",
    "# Add OOF predictions for downstream analysis\n",
    "df[\"oof_pred\"] = oof_pred\n",
    "print(\"\\nOOF predictions added to df as column 'oof_pred'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 11:29:09,422] A new study created in memory with name: no-name-8795fd82-4f3e-4625-9021-0c1e28b2a5cc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14adbe73b3f3443d8fb6d6c36e5af890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 11:29:15,846] Trial 0 finished with value: 0.4956714076543567 and parameters: {'learning_rate': 0.014929821183551656, 'num_leaves': 63, 'max_depth': 11, 'feature_fraction': 0.7990188904449786, 'bagging_fraction': 0.7347601473022568, 'bagging_freq': 7, 'min_data_in_leaf': 24, 'lambda_l1': 0.00035880580984464427, 'lambda_l2': 4.372876788456346e-05, 'cat_l2': 1.9553739164928396, 'cat_smooth': 19.703160445068367}. Best is trial 0 with value: 0.4956714076543567.\n",
      "[I 2025-11-29 11:29:18,003] Trial 1 finished with value: 0.5343254322937263 and parameters: {'learning_rate': 0.016609641913127336, 'num_leaves': 155, 'max_depth': 3, 'feature_fraction': 0.8381617417075253, 'bagging_fraction': 0.8151863440293132, 'bagging_freq': 5, 'min_data_in_leaf': 35, 'lambda_l1': 2.4570458486997784, 'lambda_l2': 0.0012727180573610755, 'cat_l2': 2.810506706950755, 'cat_smooth': 5.177589216843952}. Best is trial 0 with value: 0.4956714076543567.\n",
      "[I 2025-11-29 11:29:19,312] Trial 2 finished with value: 0.5335291952438785 and parameters: {'learning_rate': 0.06299448630172164, 'num_leaves': 108, 'max_depth': 1, 'feature_fraction': 0.6183134309397832, 'bagging_fraction': 0.6665377212104856, 'bagging_freq': 4, 'min_data_in_leaf': 108, 'lambda_l1': 0.022261473815015684, 'lambda_l2': 5.435362174492642e-08, 'cat_l2': 12.198675453858414, 'cat_smooth': 17.685138176392286}. Best is trial 0 with value: 0.4956714076543567.\n",
      "[I 2025-11-29 11:29:21,996] Trial 3 finished with value: 0.42699110261872253 and parameters: {'learning_rate': 0.14473163325465535, 'num_leaves': 158, 'max_depth': 4, 'feature_fraction': 0.8129863326802423, 'bagging_fraction': 0.6488863921777788, 'bagging_freq': 2, 'min_data_in_leaf': 53, 'lambda_l1': 0.01662946156094897, 'lambda_l2': 5.599307617517808e-06, 'cat_l2': 8.015813847959098, 'cat_smooth': 9.679787910373802}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:23,231] Trial 4 finished with value: 0.5858479453846626 and parameters: {'learning_rate': 0.02235636957874407, 'num_leaves': 61, 'max_depth': 1, 'feature_fraction': 0.7840761464559576, 'bagging_fraction': 0.9416575604254156, 'bagging_freq': 9, 'min_data_in_leaf': 52, 'lambda_l1': 0.11266937326105937, 'lambda_l2': 1.3329583278935616e-06, 'cat_l2': 3.2498625950685356, 'cat_smooth': 10.682913442792547}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:27,006] Trial 5 finished with value: 0.4482456172962281 and parameters: {'learning_rate': 0.04561730806810399, 'num_leaves': 205, 'max_depth': 5, 'feature_fraction': 0.9206476226410409, 'bagging_fraction': 0.9896606593901538, 'bagging_freq': 6, 'min_data_in_leaf': 32, 'lambda_l1': 2.8296654506530524e-05, 'lambda_l2': 1.1655137104049483e-06, 'cat_l2': 16.85479120591722, 'cat_smooth': 1.5023099377208537}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:31,774] Trial 6 finished with value: 0.5225776060009975 and parameters: {'learning_rate': 0.013765575960226002, 'num_leaves': 41, 'max_depth': 7, 'feature_fraction': 0.6684138667265994, 'bagging_fraction': 0.8898729081295482, 'bagging_freq': 9, 'min_data_in_leaf': 69, 'lambda_l1': 0.011006029878809267, 'lambda_l2': 0.00040437827958837903, 'cat_l2': 16.092363992659394, 'cat_smooth': 1.645338980229143}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:41,352] Trial 7 finished with value: 0.49929801180178196 and parameters: {'learning_rate': 0.010844261629758494, 'num_leaves': 118, 'max_depth': -1, 'feature_fraction': 0.9855806178232831, 'bagging_fraction': 0.611446343009496, 'bagging_freq': 6, 'min_data_in_leaf': 42, 'lambda_l1': 1.5903261424474858e-06, 'lambda_l2': 2.1037392271068854e-06, 'cat_l2': 15.253165386572604, 'cat_smooth': 8.095020475414685}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:48,432] Trial 8 finished with value: 0.5136660675499153 and parameters: {'learning_rate': 0.016140530973226767, 'num_leaves': 80, 'max_depth': 8, 'feature_fraction': 0.6233828234228725, 'bagging_fraction': 0.7844751883099391, 'bagging_freq': 6, 'min_data_in_leaf': 98, 'lambda_l1': 3.3025666624223042, 'lambda_l2': 2.536338248826646e-07, 'cat_l2': 1.0431451119491997, 'cat_smooth': 6.364998251779861}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:53,849] Trial 9 finished with value: 0.4273841712451465 and parameters: {'learning_rate': 0.1552949068773498, 'num_leaves': 53, 'max_depth': 12, 'feature_fraction': 0.877461815945742, 'bagging_fraction': 0.8397509696009301, 'bagging_freq': 8, 'min_data_in_leaf': 56, 'lambda_l1': 1.6109700124200373e-05, 'lambda_l2': 0.04629484618204636, 'cat_l2': 4.473435792572451, 'cat_smooth': 12.792639344805936}. Best is trial 3 with value: 0.42699110261872253.\n",
      "[I 2025-11-29 11:29:56,205] Trial 10 finished with value: 0.4259981632298725 and parameters: {'learning_rate': 0.19495894498767782, 'num_leaves': 240, 'max_depth': 4, 'feature_fraction': 0.7354141807463657, 'bagging_fraction': 0.6762812988318002, 'bagging_freq': 1, 'min_data_in_leaf': 90, 'lambda_l1': 1.8154899690505746e-08, 'lambda_l2': 1.6395482838211648, 'cat_l2': 8.167923256801577, 'cat_smooth': 14.23261312273493}. Best is trial 10 with value: 0.4259981632298725.\n",
      "[I 2025-11-29 11:29:58,624] Trial 11 finished with value: 0.4258224906437233 and parameters: {'learning_rate': 0.19423551313849757, 'num_leaves': 248, 'max_depth': 4, 'feature_fraction': 0.7188467464781771, 'bagging_fraction': 0.7174201568152835, 'bagging_freq': 1, 'min_data_in_leaf': 89, 'lambda_l1': 3.466796629120111e-08, 'lambda_l2': 1.587591685462263, 'cat_l2': 7.585658627017296, 'cat_smooth': 14.72334300724338}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:06,556] Trial 12 finished with value: 0.428583686124728 and parameters: {'learning_rate': 0.19053542593294456, 'num_leaves': 255, 'max_depth': 8, 'feature_fraction': 0.7182139923080009, 'bagging_fraction': 0.7173650111949885, 'bagging_freq': 1, 'min_data_in_leaf': 87, 'lambda_l1': 1.3064735532928293e-08, 'lambda_l2': 7.921281792748417, 'cat_l2': 8.107089737019225, 'cat_smooth': 14.889515453129562}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:08,263] Trial 13 finished with value: 0.4657366899049011 and parameters: {'learning_rate': 0.10210643741093745, 'num_leaves': 251, 'max_depth': 2, 'feature_fraction': 0.7291268996298301, 'bagging_fraction': 0.7213120319096783, 'bagging_freq': 3, 'min_data_in_leaf': 82, 'lambda_l1': 1.0616763055115197e-08, 'lambda_l2': 4.524995437136187, 'cat_l2': 11.319341640613269, 'cat_smooth': 15.268189721120601}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:12,850] Trial 14 finished with value: 0.4283080516413215 and parameters: {'learning_rate': 0.087641731358995, 'num_leaves': 206, 'max_depth': 6, 'feature_fraction': 0.7268735913138576, 'bagging_fraction': 0.6837408415009737, 'bagging_freq': 1, 'min_data_in_leaf': 118, 'lambda_l1': 2.1322135664755766e-07, 'lambda_l2': 0.1570907010954322, 'cat_l2': 6.778214379957061, 'cat_smooth': 13.659645348519776}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:27,504] Trial 15 finished with value: 0.4300242626218619 and parameters: {'learning_rate': 0.1013438761039562, 'num_leaves': 214, 'max_depth': -1, 'feature_fraction': 0.6745960009859399, 'bagging_fraction': 0.7650037562527129, 'bagging_freq': 3, 'min_data_in_leaf': 77, 'lambda_l1': 2.4868205899739133e-07, 'lambda_l2': 0.18524709122498698, 'cat_l2': 13.228960112460529, 'cat_smooth': 16.862610644382176}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:30,159] Trial 16 finished with value: 0.47858634767155267 and parameters: {'learning_rate': 0.034148223578109406, 'num_leaves': 224, 'max_depth': 4, 'feature_fraction': 0.7669291893715632, 'bagging_fraction': 0.6138757957561007, 'bagging_freq': 2, 'min_data_in_leaf': 96, 'lambda_l1': 1.616571640925693e-07, 'lambda_l2': 0.01020756166819263, 'cat_l2': 19.17960783926418, 'cat_smooth': 11.461652453070991}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:40,245] Trial 17 finished with value: 0.4305979192769466 and parameters: {'learning_rate': 0.19773288353405524, 'num_leaves': 168, 'max_depth': 10, 'feature_fraction': 0.6668789509285482, 'bagging_fraction': 0.6983760518936274, 'bagging_freq': 1, 'min_data_in_leaf': 65, 'lambda_l1': 7.2528886620796645e-06, 'lambda_l2': 1.435528009143169, 'cat_l2': 5.519632847551958, 'cat_smooth': 19.59347530960482}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:45,066] Trial 18 finished with value: 0.4269997376858316 and parameters: {'learning_rate': 0.12932158631265944, 'num_leaves': 187, 'max_depth': 6, 'feature_fraction': 0.8543202629199815, 'bagging_fraction': 0.75636601296129, 'bagging_freq': 4, 'min_data_in_leaf': 95, 'lambda_l1': 0.0002955247789475336, 'lambda_l2': 0.0026460925922484496, 'cat_l2': 9.025026822165527, 'cat_smooth': 16.937528344105594}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:47,218] Trial 19 finished with value: 0.4536439958849634 and parameters: {'learning_rate': 0.07147558721001723, 'num_leaves': 20, 'max_depth': 3, 'feature_fraction': 0.756089412088727, 'bagging_fraction': 0.8305252316241503, 'bagging_freq': 2, 'min_data_in_leaf': 111, 'lambda_l1': 5.5819595002273264e-08, 'lambda_l2': 0.7056298607415307, 'cat_l2': 10.153430083174333, 'cat_smooth': 12.74920139849444}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:48,440] Trial 20 finished with value: 0.5445578024226314 and parameters: {'learning_rate': 0.04994107556869158, 'num_leaves': 229, 'max_depth': 1, 'feature_fraction': 0.6939671637069058, 'bagging_fraction': 0.6419824448147516, 'bagging_freq': 3, 'min_data_in_leaf': 88, 'lambda_l1': 9.060245895859156e-07, 'lambda_l2': 0.02977385147476316, 'cat_l2': 5.028848501726347, 'cat_smooth': 8.679879273372997}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:51,052] Trial 21 finished with value: 0.42791316890464903 and parameters: {'learning_rate': 0.13665891554083762, 'num_leaves': 181, 'max_depth': 4, 'feature_fraction': 0.8213235470632523, 'bagging_fraction': 0.6504712074813519, 'bagging_freq': 2, 'min_data_in_leaf': 58, 'lambda_l1': 0.0008345318734659105, 'lambda_l2': 1.925297410281374e-05, 'cat_l2': 7.539461483209457, 'cat_smooth': 9.69605824753869}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:54,116] Trial 22 finished with value: 0.4266452068261115 and parameters: {'learning_rate': 0.14491968516721485, 'num_leaves': 244, 'max_depth': 5, 'feature_fraction': 0.7559446904245959, 'bagging_fraction': 0.6771354787555613, 'bagging_freq': 1, 'min_data_in_leaf': 76, 'lambda_l1': 0.30532510027340604, 'lambda_l2': 3.37430195079183e-05, 'cat_l2': 10.053876686816572, 'cat_smooth': 14.599970626492778}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:30:57,112] Trial 23 finished with value: 0.4259951165569517 and parameters: {'learning_rate': 0.19825749177948018, 'num_leaves': 237, 'max_depth': 5, 'feature_fraction': 0.7408042309031859, 'bagging_fraction': 0.7428176154198194, 'bagging_freq': 1, 'min_data_in_leaf': 74, 'lambda_l1': 0.636631563125052, 'lambda_l2': 4.6403919385662764e-05, 'cat_l2': 10.261776329616707, 'cat_smooth': 14.598128612822098}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:03,538] Trial 24 finished with value: 0.42826122504410663 and parameters: {'learning_rate': 0.19054346223307853, 'num_leaves': 230, 'max_depth': 7, 'feature_fraction': 0.7045941941513755, 'bagging_fraction': 0.7403117421748456, 'bagging_freq': 4, 'min_data_in_leaf': 103, 'lambda_l1': 0.0018502300499589333, 'lambda_l2': 0.00018294310378845987, 'cat_l2': 13.227424374349232, 'cat_smooth': 15.846371387246277}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:05,294] Trial 25 finished with value: 0.4392917910578256 and parameters: {'learning_rate': 0.11659004025500605, 'num_leaves': 239, 'max_depth': 3, 'feature_fraction': 0.6418563825080685, 'bagging_fraction': 0.7887212833076519, 'bagging_freq': 1, 'min_data_in_leaf': 86, 'lambda_l1': 5.668104134311975e-05, 'lambda_l2': 0.7919790741865158, 'cat_l2': 6.173116002930186, 'cat_smooth': 18.25784306068091}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:17,345] Trial 26 finished with value: 0.44678811035314814 and parameters: {'learning_rate': 0.030523625959656384, 'num_leaves': 195, 'max_depth': 9, 'feature_fraction': 0.7508292339169308, 'bagging_fraction': 0.7058461440965235, 'bagging_freq': 3, 'min_data_in_leaf': 65, 'lambda_l1': 6.765898154024401e-08, 'lambda_l2': 0.003889582262557943, 'cat_l2': 9.337040662733232, 'cat_smooth': 12.021139602783556}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:21,120] Trial 27 finished with value: 0.43347796056947363 and parameters: {'learning_rate': 0.0798087104686162, 'num_leaves': 131, 'max_depth': 5, 'feature_fraction': 0.6997162367497922, 'bagging_fraction': 0.858708669011277, 'bagging_freq': 2, 'min_data_in_leaf': 75, 'lambda_l1': 2.0717457431211583e-06, 'lambda_l2': 0.00014896470244688757, 'cat_l2': 11.301094676577549, 'cat_smooth': 13.534229389091124}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:22,478] Trial 28 finished with value: 0.44962718810638175 and parameters: {'learning_rate': 0.16734229387257082, 'num_leaves': 219, 'max_depth': 2, 'feature_fraction': 0.7849351695721062, 'bagging_fraction': 0.7732113276642139, 'bagging_freq': 1, 'min_data_in_leaf': 95, 'lambda_l1': 0.7178875647863884, 'lambda_l2': 1.223883039244925e-08, 'cat_l2': 13.20675119911212, 'cat_smooth': 16.3713667574968}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:28,253] Trial 29 finished with value: 0.427691114616056 and parameters: {'learning_rate': 0.11424854197309768, 'num_leaves': 89, 'max_depth': 7, 'feature_fraction': 0.8819121681632179, 'bagging_fraction': 0.7383650729186806, 'bagging_freq': 5, 'min_data_in_leaf': 119, 'lambda_l1': 8.65274107983893, 'lambda_l2': 0.16028369579762564, 'cat_l2': 6.962213664059508, 'cat_smooth': 18.9297983965118}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:33,109] Trial 30 finished with value: 0.4337908527392802 and parameters: {'learning_rate': 0.0634990661249779, 'num_leaves': 240, 'max_depth': 6, 'feature_fraction': 0.7949158444701431, 'bagging_fraction': 0.7442014183109655, 'bagging_freq': 7, 'min_data_in_leaf': 82, 'lambda_l1': 9.662944168542794e-05, 'lambda_l2': 2.5881544990128122, 'cat_l2': 3.897623082368252, 'cat_smooth': 13.682389059257236}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:36,155] Trial 31 finished with value: 0.426348180305051 and parameters: {'learning_rate': 0.1621928628810912, 'num_leaves': 253, 'max_depth': 5, 'feature_fraction': 0.7439403618554288, 'bagging_fraction': 0.6814605732223997, 'bagging_freq': 1, 'min_data_in_leaf': 74, 'lambda_l1': 0.724263669572509, 'lambda_l2': 7.100801532728571e-05, 'cat_l2': 10.15324147740385, 'cat_smooth': 14.703551384498951}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:38,812] Trial 32 finished with value: 0.42625975452846915 and parameters: {'learning_rate': 0.17059955575713445, 'num_leaves': 255, 'max_depth': 4, 'feature_fraction': 0.7428683659014651, 'bagging_fraction': 0.6945356703525929, 'bagging_freq': 2, 'min_data_in_leaf': 20, 'lambda_l1': 0.0841277441773089, 'lambda_l2': 1.0485605939122116e-05, 'cat_l2': 11.30650795867191, 'cat_smooth': 14.731380449699179}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:40,870] Trial 33 finished with value: 0.4279711348759416 and parameters: {'learning_rate': 0.19427038763594953, 'num_leaves': 234, 'max_depth': 3, 'feature_fraction': 0.6838699768540387, 'bagging_fraction': 0.7063617053181497, 'bagging_freq': 2, 'min_data_in_leaf': 23, 'lambda_l1': 0.06417999650043028, 'lambda_l2': 9.874403776306675e-06, 'cat_l2': 11.239710044504603, 'cat_smooth': 17.84436815433749}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:43,314] Trial 34 finished with value: 0.42670041123090574 and parameters: {'learning_rate': 0.16094122609401196, 'num_leaves': 256, 'max_depth': 4, 'feature_fraction': 0.7288802520975277, 'bagging_fraction': 0.6413599334743851, 'bagging_freq': 10, 'min_data_in_leaf': 39, 'lambda_l1': 0.005423373284300141, 'lambda_l2': 3.371740179975999e-07, 'cat_l2': 8.746337694850745, 'cat_smooth': 11.402414703126873}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:44,922] Trial 35 finished with value: 0.4622744837086574 and parameters: {'learning_rate': 0.11217628110439767, 'num_leaves': 207, 'max_depth': 2, 'feature_fraction': 0.7796523797740714, 'bagging_fraction': 0.6593380810884115, 'bagging_freq': 2, 'min_data_in_leaf': 45, 'lambda_l1': 0.03553830996190947, 'lambda_l2': 0.0007950829868961503, 'cat_l2': 14.622523194965508, 'cat_smooth': 15.890377771976189}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:46,964] Trial 36 finished with value: 0.435966244130564 and parameters: {'learning_rate': 0.13124201283308454, 'num_leaves': 171, 'max_depth': 3, 'feature_fraction': 0.649175098360375, 'bagging_fraction': 0.8088137039310337, 'bagging_freq': 4, 'min_data_in_leaf': 102, 'lambda_l1': 2.9477861105305934, 'lambda_l2': 2.641976742317848e-06, 'cat_l2': 2.0304390034963715, 'cat_smooth': 14.111648434850654}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:49,492] Trial 37 finished with value: 0.42658270160445494 and parameters: {'learning_rate': 0.17055818962610877, 'num_leaves': 196, 'max_depth': 4, 'feature_fraction': 0.8212730116246401, 'bagging_fraction': 0.6247303377919025, 'bagging_freq': 3, 'min_data_in_leaf': 32, 'lambda_l1': 0.14925119718261784, 'lambda_l2': 5.840666535421463e-05, 'cat_l2': 12.170492116728461, 'cat_smooth': 0.2586986411906942}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:31:50,826] Trial 38 finished with value: 0.584770296120954 and parameters: {'learning_rate': 0.02278381777487172, 'num_leaves': 148, 'max_depth': 1, 'feature_fraction': 0.7103494113061135, 'bagging_fraction': 0.7253384681272635, 'bagging_freq': 2, 'min_data_in_leaf': 20, 'lambda_l1': 3.8901624675072586e-08, 'lambda_l2': 2.7389313460589756e-07, 'cat_l2': 7.990103924320989, 'cat_smooth': 10.520298678719065}. Best is trial 11 with value: 0.4258224906437233.\n",
      "[I 2025-11-29 11:32:04,383] Trial 39 finished with value: 0.4309844005427171 and parameters: {'learning_rate': 0.09328912490614115, 'num_leaves': 223, 'max_depth': 0, 'feature_fraction': 0.9956910406509363, 'bagging_fraction': 0.7019723431240138, 'bagging_freq': 1, 'min_data_in_leaf': 91, 'lambda_l1': 0.0043197701552696146, 'lambda_l2': 1.426778383422384e-05, 'cat_l2': 6.003430309995711, 'cat_smooth': 3.8376576988916646}. Best is trial 11 with value: 0.4258224906437233.\n",
      "\n",
      "==================== BEST PARAMETERS ====================\n",
      "{'learning_rate': 0.19423551313849757, 'num_leaves': 248, 'max_depth': 4, 'feature_fraction': 0.7188467464781771, 'bagging_fraction': 0.7174201568152835, 'bagging_freq': 1, 'min_data_in_leaf': 89, 'lambda_l1': 3.466796629120111e-08, 'lambda_l2': 1.587591685462263, 'cat_l2': 7.585658627017296, 'cat_smooth': 14.72334300724338}\n",
      "\n",
      "Best CV LogLoss = 0.4258224906437233\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. PREP DATA\n",
    "# =========================================================\n",
    "\n",
    "df = train.copy()\n",
    "\n",
    "target = \"y_passXtremeDurability\"\n",
    "categorical_cols = [\"alloy\", \"cutTemp\", \"rollTemp\",\n",
    "                    \"topEdgeMicroChipping\", \"blockSource\", \"machineRestart\"]\n",
    "\n",
    "# Label encode categoricals\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "X = df.drop(columns=[target, \"ID\"])\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. OPTUNA OBJECTIVE FUNCTION\n",
    "# =========================================================\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,\n",
    "        \n",
    "        # Hyperparameters to tune â†“\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 256),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 120),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"cat_l2\": trial.suggest_float(\"cat_l2\", 0.0, 20.0),\n",
    "        \"cat_smooth\": trial.suggest_float(\"cat_smooth\", 0.0, 20.0),\n",
    "    }\n",
    "\n",
    "    # 5-fold CV\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_losses = []\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(\n",
    "            X_train, y_train, categorical_feature=categorical_cols\n",
    "        )\n",
    "        valid_data = lgb.Dataset(\n",
    "            X_valid, y_valid, categorical_feature=categorical_cols\n",
    "        )\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_valid)\n",
    "        loss = log_loss(y_valid, preds)\n",
    "        fold_losses.append(loss)\n",
    "\n",
    "    return np.mean(fold_losses)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. RUN OPTUNA STUDY\n",
    "# =========================================================\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n==================== BEST PARAMETERS ====================\")\n",
    "print(study.best_params)\n",
    "print(\"\\nBest CV LogLoss =\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model trained on full dataset.\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42\n",
    "})\n",
    "\n",
    "train_data_full = lgb.Dataset(X, y, categorical_feature=categorical_cols)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    train_data_full,\n",
    "    num_boost_round=2000,\n",
    "    callbacks=[lgb.log_evaluation(period=200)]\n",
    ")\n",
    "\n",
    "print(\"\\nFinal model trained on full dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_lightgbm.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# FIX: Encode test categorical columns\n",
    "# =============================\n",
    "\n",
    "test_df_fixed = test.copy()   # keep original safe\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[col].astype(str))   # fit on **train only**\n",
    "    test_df_fixed[col] = le.transform(test_df_fixed[col].astype(str))\n",
    "\n",
    "# =============================\n",
    "# Prepare test features\n",
    "# =============================\n",
    "X_test = test_df_fixed.drop(columns=[\"ID\"])\n",
    "\n",
    "# =============================\n",
    "# Predict\n",
    "# =============================\n",
    "test_pred = final_model.predict(X_test)\n",
    "\n",
    "# =============================\n",
    "# Build Submission\n",
    "# =============================\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_df_fixed[\"ID\"],\n",
    "    \"y_passXtremeDurability\": test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_lightgbm.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission_lightgbm.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
